{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de documentos: 614\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "\n",
    "# Implementação de uma classe auxiliar para fazer stemming\n",
    "class Stemmer:\n",
    "  def __init__(self):\n",
    "    self.stemmer = SnowballStemmer('portuguese')\n",
    "\n",
    "  def stem(self, text):\n",
    "    # Utiliza uma expressão regular para substituir caracteres\n",
    "    # especiais por espaços\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    \n",
    "    # Remove espaços extras no início e no final\n",
    "    text = text.strip()\n",
    "    \n",
    "    text = text.split()\n",
    "    return [self.stemmer.stem(word) for word in text]\n",
    "\n",
    "\n",
    "# Implementação do indexador BM25 para documentos\n",
    "class BM25Indexer:\n",
    "  stemmer = Stemmer()\n",
    "\n",
    "  def __init__(self, corpus, k1=1.2, b=0.75):\n",
    "    # Inicializa o indexador BM25 com o corpus de documentos\n",
    "    # e parâmetros k1 e b. k1 e b são parâmetros de ajuste e geralmente\n",
    "    # são definidos como k1 = 1.2 e b = 0.75 (pelo Elasticsearch,\n",
    "    # por exemplo)\n",
    "    self.corpus = corpus # corpus de documentos\n",
    "    self.k1 = k1 # ajuda a determinar as características de saturação\n",
    "    self.b = b # é um multiplicador da razão entre comprimentos\n",
    "    self.doc_lengths = [len(doc) for doc in corpus]\n",
    "    self.avg_doc_length = sum(self.doc_lengths) / len(self.doc_lengths)\n",
    "    self.doc_term_freqs = [self.get_doc_term_freqs(doc) for doc in corpus]\n",
    "    self.total_docs = len(corpus)\n",
    "    self.doc_freqs = self.get_doc_freqs()\n",
    "\n",
    "  def get_doc_term_freqs(self, doc):\n",
    "    # Calcula as frequências de termos para cada campo em um documento\n",
    "    term_freqs = {}\n",
    "    terms = self.tokenize(doc)\n",
    "    for term in terms:\n",
    "      term_freqs[term] = term_freqs.get(term, 0) + 1\n",
    "    return term_freqs\n",
    "\n",
    "  def get_doc_freqs(self):\n",
    "    # Calcula as frequências de documentos para cada termo em todos\n",
    "    # os documentos\n",
    "    doc_freqs = {}\n",
    "    for doc in self.corpus:\n",
    "      terms = set(self.tokenize(doc))\n",
    "      for term in terms:\n",
    "        doc_freqs[term] = doc_freqs.get(term, 0) + 1\n",
    "    return doc_freqs\n",
    "\n",
    "  def get_idf(self, term):\n",
    "    # Calcula o fator IDF (Inverse Document Frequency) para um termo\n",
    "    doc_freq = self.doc_freqs.get(term, 0)\n",
    "    return math.log(\n",
    "      (self.total_docs - doc_freq + 0.5) / (doc_freq + 0.5) + 1.0\n",
    "    )\n",
    "\n",
    "  def get_bm25_score(self, query, doc):\n",
    "    # Calcula o escore BM25 para um documento em relação a uma consulta\n",
    "    score = 0\n",
    "    terms = self.tokenize(query)\n",
    "    for term in terms:\n",
    "      idf = self.get_idf(term)\n",
    "      doc_freq = self.doc_term_freqs[doc].get(term, 0)\n",
    "      doc_length = self.doc_lengths[doc]\n",
    "      numerator = doc_freq * (self.k1 + 1)\n",
    "      denominator = (doc_freq + self.k1 * (1 - self.b + self.b * doc_length / self.avg_doc_length))\n",
    "      score += idf * numerator / denominator\n",
    "    return score\n",
    "\n",
    "  def tokenize(self, text):\n",
    "    # Implementa a lógica de tokenização\n",
    "    # Vamos usar o Snowball Stemmer para o Português\n",
    "    return self.stemmer.stem(text)\n",
    "\n",
    "# Consulta\n",
    "def search(query, fields, top_n=10):\n",
    "  # Implementa a lógica de busca\n",
    "  scores = []\n",
    "  for i, doc in enumerate(corpus):\n",
    "    peso_total = 0\n",
    "    score = 0\n",
    "    for field in fields:\n",
    "      peso = field['peso']\n",
    "      peso_total += peso\n",
    "      field = field['campo']\n",
    "      score += bm25_indexer[field].get_bm25_score(query, i) * peso\n",
    "    score /= peso_total\n",
    "    scores.append((i, score))\n",
    "  scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "  return scores[:top_n]\n",
    "\n",
    "corpus = []\n",
    "# corpus de documentos lido do arquivo JSON C:\\Users\\julio\\Projects\\UFRJ\\hybrop2p\\poc\\parsed_doutorados.json\n",
    "with open('parsed_doutorados.json', 'r', encoding='utf-8') as f:\n",
    "  corpus = json.load(f)\n",
    "\n",
    "print(f\"Total de documentos: {len(corpus)}\")\n",
    "\n",
    "# Inicializa o indexador BM25\n",
    "bm25_indexer = {\n",
    "  'title': BM25Indexer([doc['title'] for doc in corpus]),\n",
    "  'author': BM25Indexer([doc['author'] for doc in corpus]),\n",
    "  'advisor': BM25Indexer([doc['advisor'] for doc in corpus]),\n",
    "  'abstract': BM25Indexer([doc['abstract'] for doc in corpus]),\n",
    "  'keywords': BM25Indexer([doc['keywords'] for doc in corpus]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 documentos para a consulta 'sistemas distribuídos' nos campos '[{'campo': 'title', 'peso': 1}, {'campo': 'author', 'peso': 1}, {'campo': 'advisor', 'peso': 1}, {'campo': 'abstract', 'peso': 1}, {'campo': 'keywords', 'peso': 1}]':\n",
      "\n",
      "Documento: Projeto ótimo de múltiplos sistemas passivos de absorção distribuídos espacialmente\n",
      "Score: 3.435636631100766\n",
      "Autores: Costa, Mariana Miglio Americano da\n",
      "Palavras-chave: Sistema Passivo de Absorção; Parâmetros incertos; Simulação de Monte Carlo; Análise de robustez\n",
      "URL: https://pantheon.ufrj.br/bitstream/11422/14005/1/MarianaMiglioAmericanoDaCosta.pdf\n",
      "\n",
      "Documento: Estimativas de dose devido a acidentes nucleares baseadas em medidas de campo e otimização por enxame de partículas\n",
      "Score: 2.8907655929688065\n",
      "Autores: Przewodowski Filho, André\n",
      "Palavras-chave: Engenharia Nuclear; Problema inverso; Correção distribuição de dose\n",
      "URL: https://pantheon.ufrj.br/bitstream/11422/11119/2/877647.pdf\n",
      "\n",
      "Documento: Estratégia geral de ondas de mensagens para desenvolvimento de tarefas em enxames de robôs\n",
      "Score: 2.679437067960021\n",
      "Autores: Silva Junior, Luneque Del Rio de Souza e\n",
      "Palavras-chave: Engenharia de Sistemas e Computação; Algoritmos distribuídos; Transmissão de mensagens\n",
      "URL: https://pantheon.ufrj.br/bitstream/11422/8709/1/879610.pdf\n",
      "\n",
      "Documento: Reconstrução da distribuição da densidade de potência heterogênea pino a pino usando o método dos pseudoharmônicos\n",
      "Score: 2.661788453293332\n",
      "Autores: Teixeira, Danielle Gonçalves\n",
      "Palavras-chave: Engenharia nuclear; Método dos pseudo-harmônicos; Reconstrução da densidade de potência heterogênea pino a pino\n",
      "URL: https://pantheon.ufrj.br/bitstream/11422/11295/1/877626.pdf\n",
      "\n",
      "Documento: Taxonomia e distribuição geográfica dos Monstrilloida (Copepoda - Crustacea) do Atlântico sul ocidental\n",
      "Score: 2.645209451097389\n",
      "Autores: Dias, Cristina de Oliveira\n",
      "Palavras-chave: Distribuição espacial; Crustáceos; Copépodes; Monstrilloida; Atlântico Sul;  Oceano\n",
      "URL: https://pantheon.ufrj.br/bitstream/11422/3460/3/567114.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Teste\n",
    "query = 'sistemas distribuídos'\n",
    "fields = [\n",
    "  {'campo': 'title', 'peso': 3},\n",
    "  {'campo': 'author', 'peso': 1},\n",
    "  {'campo': 'advisor', 'peso': 1},\n",
    "  {'campo': 'abstract', 'peso': 2},\n",
    "  {'campo': 'keywords', 'peso': 3},\n",
    "]\n",
    "top_n = 5\n",
    "scores = search(query, fields, top_n)\n",
    "\n",
    "print(f\"Top {top_n} documentos para a consulta '{query}' nos campos '{fields}':\")\n",
    "print()\n",
    "for i, score in scores:\n",
    "  print(f\"Documento: {corpus[i]['title']}\")\n",
    "  print(f\"Score: {score}\")\n",
    "  print(f\"Autores: {corpus[i]['author']}\")\n",
    "  print(f\"Palavras-chave: {corpus[i]['keywords'].replace(',', '; ')}\")\n",
    "  print(f\"URL: {corpus[i]['pdfUrl']}\")\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
